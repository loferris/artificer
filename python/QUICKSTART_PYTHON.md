# Python Microservice Quick Start ðŸš€

**Goal:** Get the Python OCR service running in 5 minutes

## Step 1: Start the Python Service

```bash
# From project root
docker-compose up python-ocr -d

# Check it's running
curl http://localhost:8000/health
```

Expected output:
```json
{
  "status": "ok",
  "service": "artificer-python-ocr",
  "version": "0.1.0",
  "processors": {
    "pdf": true,
    "ocr_openai": true,
    "ocr_tesseract": true
  }
}
```

## Step 2: Test PDF Processing

```bash
# Create a test script
cat > test-python-service.sh << 'EOF'
#!/bin/bash

# Create a simple test PDF (or use your own)
echo "Testing Python PDF service..."

# Base64 encode a test PDF
# (You'll need a real PDF file here - download or create one)
PDF_BASE64=$(base64 -i your-test.pdf)

# Call the Python service
curl -X POST http://localhost:8000/api/pdf/extract \
  -H "Content-Type: application/json" \
  -d "{\"pdf_data\": \"$PDF_BASE64\"}" | jq

echo "Done! Check the processing time - should be <20ms for small PDFs"
EOF

chmod +x test-python-service.sh
./test-python-service.sh
```

## Step 3: Verify TypeScript Integration

The TypeScript application will automatically use Python if it's running:

```bash
# Start the full application
docker-compose up -d

# Check TypeScript logs - should see "Python OCR service is available"
docker-compose logs api | grep Python
```

## Step 4: Compare Performance

### TypeScript (old):
```bash
# Process a 10-page PDF with TypeScript
time curl -X POST http://localhost:3001/api/images/process-pdf \
  -H "Authorization: Bearer your-api-key" \
  -d '{"pdfData": "base64-data"}'

# Expected: ~100-200ms
```

### Python (new):
```bash
# Process same PDF with Python
time curl -X POST http://localhost:8000/api/pdf/extract \
  -d '{"pdf_data": "base64-data"}'

# Expected: ~5-20ms â† 10-20x faster!
```

## Interactive API Docs

Visit http://localhost:8000/docs for Swagger UI where you can:
- Test all endpoints
- See request/response schemas
- Try OCR with sample images

## What Just Happened?

1. **Python service started** on port 8000
2. **TypeScript detected it** via health check
3. **PDF requests now route** to Python automatically
4. **10-20x faster** PDF processing! ðŸŽ‰

## Troubleshooting

### "Connection refused" on port 8000

```bash
# Check if service is running
docker-compose ps python-ocr

# View logs
docker-compose logs python-ocr

# Rebuild if needed
docker-compose build python-ocr
docker-compose up python-ocr
```

### "Module not found" errors

```bash
# Rebuild with fresh dependencies
docker-compose down
docker-compose build --no-cache python-ocr
docker-compose up python-ocr
```

### TypeScript not using Python

Check environment variable:
```bash
# In .env or .env.local
PYTHON_OCR_URL=http://localhost:8000

# Or for Docker networking
PYTHON_OCR_URL=http://python-ocr:8000
```

## Next Steps

Once you verify it works:

1. **Benchmark your actual PDFs** - See the real speedup
2. **Monitor costs** - Compare OCR costs before/after
3. **Add more endpoints** - Extend the Python service
4. **Consider gRPC** - For even better performance (see GRPC_VS_REST_ANALYSIS.md)

## Need Help?

```bash
# View all services
docker-compose ps

# View Python service logs
docker-compose logs -f python-ocr

# Restart Python service
docker-compose restart python-ocr

# Shell into Python container
docker-compose exec python-ocr bash
```

## Success Metrics

You'll know it's working when:
- [ ] Health check returns 200 OK
- [ ] Swagger docs loads at /docs
- [ ] PDF extraction completes in <20ms (vs 100-200ms before)
- [ ] TypeScript logs show "Python OCR service is available"
- [ ] API requests get faster responses

## Celebration Time! ðŸŽŠ

If you see sub-20ms PDF processing times, you just achieved a **10-20x speedup**!

That's what migrating to Python gets you. Now imagine the cost savings... ðŸ’°
